from xtquant import xtdata
import pandas as pd
import os
from datetime import datetime
import time
import logging

def setup_logging():
    """
    è®¾ç½®æ—¥å¿—é…ç½®
    """
    # è·å–è„šæœ¬æ‰€åœ¨ç›®å½•
    script_dir = os.path.dirname(os.path.abspath(__file__))
    
    # åˆ›å»ºlogsæ–‡ä»¶å¤¹
    logs_dir = os.path.join(script_dir, "logs")
    if not os.path.exists(logs_dir):
        os.makedirs(logs_dir)
    
    # ç”Ÿæˆå¸¦æ—¶é—´æˆ³çš„æ—¥å¿—æ–‡ä»¶å
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    log_filename = os.path.join(logs_dir, f"simple_30min_test_{timestamp}.log")
    
    # é…ç½®æ—¥å¿—
    logging.basicConfig(
        level=logging.INFO,
        format='%(asctime)s - %(levelname)s - %(message)s',
        handlers=[
            logging.FileHandler(log_filename, encoding='utf-8'),
            logging.StreamHandler()  # åŒæ—¶è¾“å‡ºåˆ°æ§åˆ¶å°
        ]
    )
    
    return log_filename

def download_30min_data_to_cache(stock_code, stock_name):
    """
    ä¸‹è½½å•ä¸ªè‚¡ç¥¨çš„30åˆ†é’Ÿæ•°æ®åˆ°æœ¬åœ°ç¼“å­˜ï¼ˆåŸºäºget_all_stocks_data.pyçš„é€»è¾‘ï¼‰
    
    Args:
        stock_code: è‚¡ç¥¨ä»£ç 
        stock_name: è‚¡ç¥¨åç§°
    
    Returns:
        bool: æ˜¯å¦æˆåŠŸä¸‹è½½
    """
    logging.info(f"å¼€å§‹ä¸‹è½½è‚¡ç¥¨ {stock_code} ({stock_name}) çš„30åˆ†é’Ÿæ•°æ®åˆ°æœ¬åœ°ç¼“å­˜...")
    
    # æ„é€ è‚¡ç¥¨ä»£ç æ ¼å¼ï¼ˆéœ€è¦æ·»åŠ äº¤æ˜“æ‰€åç¼€ï¼‰
    if stock_code.startswith('6'):
        full_code = f"{stock_code}.SH"  # ä¸Šæµ·äº¤æ˜“æ‰€
    elif stock_code.startswith('0') or stock_code.startswith('3'):
        full_code = f"{stock_code}.SZ"  # æ·±åœ³äº¤æ˜“æ‰€
    else:
        logging.warning(f"è·³è¿‡ä¸æ”¯æŒçš„è‚¡ç¥¨ä»£ç : {stock_code}")
        return False
    
    try:
        # ä¸‹è½½30åˆ†é’Ÿæ•°æ®ï¼ˆä»1990å¹´å¼€å§‹ï¼‰
        logging.info(f"ä¸‹è½½30åˆ†é’Ÿæ•°æ®åˆ°æœ¬åœ°ï¼ˆä»1990å¹´å¼€å§‹ï¼‰...")
        download_result = xtdata.download_history_data(full_code, period='30m', start_time='19900101')
        logging.info(f"30åˆ†é’Ÿæ•°æ®ä¸‹è½½ç»“æœ: {download_result}")
        logging.info(f"30åˆ†é’Ÿæ•°æ®å·²ä¸‹è½½åˆ°æœ¬åœ°ç¼“å­˜")
        return True
        
    except Exception as e:
        logging.error(f"30åˆ†é’Ÿæ•°æ®ä¸‹è½½å¤±è´¥: {e}")
        # å°è¯•é‡è¯•ä¸€æ¬¡
        try:
            logging.info("å‡†å¤‡é‡è¯•ä¸‹è½½...")
            time.sleep(2)
            download_result = xtdata.download_history_data(full_code, period='30m', start_time='19900101')
            logging.info(f"30åˆ†é’Ÿæ•°æ®é‡è¯•ä¸‹è½½ç»“æœ: {download_result}")
            logging.info(f"30åˆ†é’Ÿæ•°æ®é‡è¯•æˆåŠŸ")
            return True
        except Exception as retry_e:
            logging.error(f"30åˆ†é’Ÿæ•°æ®é‡è¯•ä¸‹è½½ä»ç„¶å¤±è´¥: {retry_e}")
            return False

def save_30min_data_to_csv(stock_code, stock_name, base_folder="test_30min_output"):
    """
    å°†å•ä¸ªè‚¡ç¥¨çš„30åˆ†é’Ÿæ•°æ®ä¿å­˜ä¸ºCSVæ–‡ä»¶ï¼ˆåŸºäºsave_stocks_to_csv.pyçš„é€»è¾‘ï¼‰
    
    Args:
        stock_code: è‚¡ç¥¨ä»£ç 
        stock_name: è‚¡ç¥¨åç§°
        base_folder: æ•°æ®ä¿å­˜çš„åŸºç¡€æ–‡ä»¶å¤¹
    
    Returns:
        tuple: (æˆåŠŸæ•°é‡, æ€»å°è¯•æ•°é‡)
    """
    logging.info(f"å¼€å§‹ä¿å­˜è‚¡ç¥¨ {stock_code} ({stock_name}) çš„30åˆ†é’Ÿæ•°æ®åˆ°CSV...")
    
    # è·å–è„šæœ¬æ‰€åœ¨ç›®å½•
    script_dir = os.path.dirname(os.path.abspath(__file__))
    base_folder = os.path.join(script_dir, base_folder)
    
    # åˆ›å»ºè‚¡ç¥¨ä¸“ç”¨æ•°æ®æ–‡ä»¶å¤¹
    stock_folder = os.path.join(base_folder, f"stock_{stock_code}_data")
    if not os.path.exists(stock_folder):
        os.makedirs(stock_folder)
        logging.info(f"åˆ›å»ºè‚¡ç¥¨æ–‡ä»¶å¤¹: {stock_folder}")
    
    # æ„é€ è‚¡ç¥¨ä»£ç æ ¼å¼
    if stock_code.startswith('6'):
        full_code = f"{stock_code}.SH"
    elif stock_code.startswith('0') or stock_code.startswith('3'):
        full_code = f"{stock_code}.SZ"
    else:
        logging.warning(f"è·³è¿‡ä¸æ”¯æŒçš„è‚¡ç¥¨ä»£ç : {stock_code}")
        return 0, 1
    
    try:
        # è·å–30åˆ†é’Ÿæ•°æ®ï¼ˆä»æœ¬åœ°ç¼“å­˜æˆ–ç›´æ¥è·å–ï¼‰
        logging.info(f"è·å–30åˆ†é’Ÿæ•°æ®ï¼ˆä»1990å¹´å¼€å§‹ï¼‰...")
        minute_data = xtdata.get_market_data([], [full_code], period='30m', start_time='19900101')
        
        if minute_data and isinstance(minute_data, dict):
            # å¤„ç†xtquantè¿”å›çš„æ•°æ®ç»“æ„
            try:
                # è·å–æ—¶é—´åºåˆ—
                time_df = minute_data.get('time')
                if time_df is not None and not time_df.empty:
                    # è·å–è‚¡ç¥¨åœ¨DataFrameä¸­çš„æ•°æ®
                    if full_code in time_df.index:
                        times = time_df.loc[full_code].values
                        
                        # æ„å»ºæ–°çš„DataFrameï¼Œè¡Œä¸ºæ—¶é—´ï¼Œåˆ—ä¸ºå„ä¸ªæŒ‡æ ‡
                        df_data = {'time': times}
                        
                        # æå–å„ä¸ªå­—æ®µçš„æ•°æ®
                        for field_name, field_df in minute_data.items():
                            if field_name != 'time' and field_df is not None and not field_df.empty:
                                if full_code in field_df.index:
                                    df_data[field_name] = field_df.loc[full_code].values
                        
                        # åˆ›å»ºæœ€ç»ˆçš„DataFrame
                        minute_df = pd.DataFrame(df_data)
                        
                        # æ·»åŠ å¯è¯»çš„æ—¥æœŸæ—¶é—´åˆ—
                        if 'time' in minute_df.columns:
                            datetime_col = pd.to_datetime(minute_df['time'], unit='ms').dt.tz_localize('UTC').dt.tz_convert('Asia/Shanghai').dt.strftime('%Y-%m-%d %H:%M:%S')
                            # é‡æ–°æ’åˆ—åˆ—é¡ºåºï¼Œå°†datetimeæ”¾åœ¨timeåé¢
                            cols = list(minute_df.columns)
                            time_idx = cols.index('time')
                            cols.insert(time_idx + 1, 'datetime')
                            minute_df['datetime'] = datetime_col
                            minute_df = minute_df[cols]
                        
                        # ä¿å­˜ä¸ºCSVæ–‡ä»¶
                        minute_filename = os.path.join(stock_folder, f"{stock_code}_30minute_history.csv")
                        minute_df.to_csv(minute_filename, encoding='utf-8-sig', index=False)
                        logging.info(f"30åˆ†é’Ÿæ•°æ®å·²ä¿å­˜åˆ°CSV: {len(minute_df)} æ¡è®°å½•")
                        logging.info(f"æ–‡ä»¶è·¯å¾„: {minute_filename}")
                        
                        # æ˜¾ç¤ºæ•°æ®ä¿¡æ¯
                        if len(minute_df) > 0:
                            logging.info(f"æ•°æ®åˆ—: {list(minute_df.columns)}")
                            logging.info(f"æ—¶é—´èŒƒå›´: {minute_df['datetime'].iloc[0]} åˆ° {minute_df['datetime'].iloc[-1]}")
                            logging.info(f"å‰3è¡Œæ•°æ®:\n{minute_df.head(3).to_string()}")
                        
                        return 1, 1
                    else:
                        logging.error(f"è‚¡ç¥¨ä»£ç  {full_code} ä¸åœ¨è¿”å›æ•°æ®ä¸­")
                        return 0, 1
                else:
                    logging.error(f"æ—¶é—´æ•°æ®ä¸ºç©º")
                    return 0, 1
            except Exception as e:
                logging.error(f"30åˆ†é’Ÿæ•°æ®å¤„ç†å¤±è´¥: {e}")
                return 0, 1
        else:
            logging.error(f"30åˆ†é’Ÿæ•°æ®è·å–å¤±è´¥: æ— æ•°æ®è¿”å›")
            return 0, 1
            
    except Exception as e:
        logging.error(f"æ•°æ®è·å–å¤±è´¥: {e}")
        return 0, 1

def test_complete_workflow(stock_code, stock_name):
    """
    æµ‹è¯•å®Œæ•´çš„å·¥ä½œæµç¨‹ï¼šä¸‹è½½æ•°æ®åˆ°ç¼“å­˜ -> ä¿å­˜ä¸ºCSV
    
    Args:
        stock_code: è‚¡ç¥¨ä»£ç 
        stock_name: è‚¡ç¥¨åç§°
    
    Returns:
        bool: æµ‹è¯•æ˜¯å¦æˆåŠŸ
    """
    logging.info(f"\n{'='*50}")
    logging.info(f"å¼€å§‹æµ‹è¯•è‚¡ç¥¨ {stock_code} ({stock_name}) çš„å®Œæ•´å·¥ä½œæµç¨‹")
    logging.info(f"{'='*50}")
    
    try:
        # æ­¥éª¤1ï¼šä¸‹è½½æ•°æ®åˆ°æœ¬åœ°ç¼“å­˜
        logging.info("æ­¥éª¤1ï¼šä¸‹è½½30åˆ†é’Ÿæ•°æ®åˆ°æœ¬åœ°ç¼“å­˜")
        download_success = download_30min_data_to_cache(stock_code, stock_name)
        
        if download_success:
            logging.info("âœ“ æ­¥éª¤1å®Œæˆï¼šæ•°æ®ä¸‹è½½æˆåŠŸ")
        else:
            logging.warning("âš  æ­¥éª¤1è­¦å‘Šï¼šæ•°æ®ä¸‹è½½å¤±è´¥ï¼Œä½†ç»§ç»­å°è¯•æ­¥éª¤2")
        
        # æ­¥éª¤2ï¼šä¿å­˜ä¸ºCSV
        logging.info("\næ­¥éª¤2ï¼šå°†æ•°æ®ä¿å­˜ä¸ºCSVæ–‡ä»¶")
        success_count, total_attempts = save_30min_data_to_csv(stock_code, stock_name)
        
        if success_count > 0:
            logging.info(f"âœ“ æ­¥éª¤2å®Œæˆï¼šCSVä¿å­˜æˆåŠŸ ({success_count}/{total_attempts})")
            logging.info(f"âœ“ è‚¡ç¥¨ {stock_code} çš„å®Œæ•´å·¥ä½œæµç¨‹æµ‹è¯•æˆåŠŸ")
            return True
        else:
            logging.error(f"âœ— æ­¥éª¤2å¤±è´¥ï¼šCSVä¿å­˜å¤±è´¥ ({success_count}/{total_attempts})")
            return False
            
    except Exception as e:
        logging.error(f"âœ— æµ‹è¯•è¿‡ç¨‹ä¸­å‘ç”Ÿå¼‚å¸¸: {e}")
        return False

def main():
    """
    ä¸»å‡½æ•°ï¼šç®€å•çš„1åˆ†é’Ÿæ•°æ®æµ‹è¯•
    """
    # è®¾ç½®æ—¥å¿—
    log_filename = setup_logging()
    logging.info(f"æµ‹è¯•æ—¥å¿—æ–‡ä»¶: {log_filename}")
    logging.info("="*60)
    logging.info("ç®€å•30åˆ†é’Ÿæ•°æ®è·å–å’Œä¿å­˜æµ‹è¯•")
    logging.info("="*60)
    
    # æµ‹è¯•å•ä¸ªè‚¡ç¥¨
    test_stock_code = "000001"
    test_stock_name = "å¹³å®‰é“¶è¡Œ"
    
    success = test_complete_workflow(test_stock_code, test_stock_name)
    
    # æµ‹è¯•æ€»ç»“
    logging.info(f"\n{'='*60}")
    logging.info("æµ‹è¯•æ€»ç»“")
    logging.info(f"{'='*60}")
    
    if success:
        logging.info("ğŸ‰ æµ‹è¯•æˆåŠŸå®Œæˆï¼")
        logging.info("30åˆ†é’Ÿæ•°æ®çš„ä¸‹è½½å’Œä¿å­˜åŠŸèƒ½æ­£å¸¸å·¥ä½œ")
    else:
        logging.error("âŒ æµ‹è¯•å¤±è´¥")
        logging.error("è¯·æ£€æŸ¥xtquantè¿æ¥å’Œæ•°æ®æƒé™")
    
    logging.info("æµ‹è¯•è„šæœ¬æ‰§è¡Œå®Œæˆ")

if __name__ == "__main__":
    main()