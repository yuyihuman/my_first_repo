# coding:utf-8
"""
çœŸæ­£çš„å­£åº¦è´¢åŠ¡æ•°æ®åˆ†æ
ä½¿ç”¨'æŒ‰æŠ¥å‘ŠæœŸ'å‚æ•°è·å–çœŸå®çš„å­£åº¦æ•°æ®
"""

import os
import json
import time
import pickle
import logging
import akshare as ak
import pandas as pd
from datetime import datetime, timedelta

# ç¼“å­˜é…ç½®
CACHE_FILE = 'stock_data_cache.pkl'
CACHE_DURATION_HOURS = 2  # ç¼“å­˜æœ‰æ•ˆæœŸ2å°æ—¶

# ç¼“å­˜åŠŸèƒ½è¯´æ˜:
# 1. æ—¥çº¿æ•°æ®å’Œæ€»è‚¡æœ¬æ•°æ®ä¼šè‡ªåŠ¨ç¼“å­˜åˆ° stock_data_cache.pkl æ–‡ä»¶
# 2. ç¼“å­˜æœ‰æ•ˆæœŸä¸º2å°æ—¶ï¼Œè¿‡æœŸåä¼šé‡æ–°è·å–æ•°æ®
# 3. ç¼“å­˜å¯ä»¥æ˜¾è‘—æé«˜é‡å¤è¿è¡Œçš„é€Ÿåº¦
# 4. å¦‚éœ€å¼ºåˆ¶åˆ·æ–°æ•°æ®ï¼Œå¯åˆ é™¤ç¼“å­˜æ–‡ä»¶

def get_stock_name_mapping():
    """
    è·å–æ‰€æœ‰Aè‚¡è‚¡ç¥¨ä»£ç å’Œåç§°çš„æ˜ å°„å…³ç³»ï¼ˆæ”¯æŒç¼“å­˜ï¼‰
    
    Returns:
        dict: è‚¡ç¥¨ä»£ç åˆ°è‚¡ç¥¨åç§°çš„æ˜ å°„å­—å…¸
    """
    # å°è¯•ä»ç¼“å­˜åŠ è½½è‚¡ç¥¨åç§°æ•°æ®
    cached_data = load_cache('stock_names')
    if cached_data is not None:
        return cached_data
    
    logger = logging.getLogger(__name__)
    logger.info("å¼€å§‹è·å–æ‰€æœ‰Aè‚¡è‚¡ç¥¨ä»£ç å’Œåç§°æ˜ å°„...")
    
    try:
        # ä½¿ç”¨akshareè·å–æ‰€æœ‰Aè‚¡è‚¡ç¥¨ä»£ç å’Œåç§° <mcreference link="https://cloud.tencent.com/developer/article/1666899" index="1">1</mcreference>
        stock_info_df = ak.stock_info_a_code_name()
        
        # åˆ›å»ºä»£ç åˆ°åç§°çš„æ˜ å°„å­—å…¸
        stock_name_mapping = {}
        
        for _, row in stock_info_df.iterrows():
            code = row['code']
            name = row['name']
            
            # ä¸ºæ·±åœ³å’Œä¸Šæµ·è‚¡ç¥¨æ·»åŠ äº¤æ˜“æ‰€åç¼€
            if code.startswith(('000', '002', '300', '301', '302')):
                full_code = f"{code}.SZ"
            elif code.startswith('6'):
                full_code = f"{code}.SH"
            else:
                full_code = code
            
            stock_name_mapping[full_code] = name
        
        logger.info(f"æˆåŠŸè·å– {len(stock_name_mapping)} åªè‚¡ç¥¨çš„åç§°æ˜ å°„")
        
        # ä¿å­˜åˆ°ç¼“å­˜
        save_cache(stock_name_mapping, 'stock_names')
        
        return stock_name_mapping
        
    except Exception as e:
        logger.error(f"è·å–è‚¡ç¥¨åç§°æ˜ å°„å¤±è´¥: {e}")
        return {}

def setup_logging():
    """
    è®¾ç½®æ—¥å¿—ç³»ç»Ÿ
    """
    # åˆ é™¤æ‰€æœ‰å†å²æ—¥å¿—æ–‡ä»¶
    import glob
    log_pattern = "quarterly_analysis_*.log"
    old_log_files = glob.glob(log_pattern)
    for old_log in old_log_files:
        try:
            os.remove(old_log)
            print(f"å·²åˆ é™¤å†å²æ—¥å¿—æ–‡ä»¶: {old_log}")
        except Exception as e:
            print(f"åˆ é™¤æ—¥å¿—æ–‡ä»¶ {old_log} å¤±è´¥: {e}")
    
    log_filename = f"quarterly_analysis_{datetime.now().strftime('%Y%m%d_%H%M%S')}.log"
    
    # é…ç½®æ—¥å¿—æ ¼å¼ï¼Œåªè¾“å‡ºåˆ°æ–‡ä»¶
    logging.basicConfig(
        level=logging.INFO,
        format='%(asctime)s - %(levelname)s - %(message)s',
        handlers=[
            logging.FileHandler(log_filename, encoding='utf-8')
        ]
    )
    
    logger = logging.getLogger(__name__)
    logger.info(f"æ—¥å¿—ç³»ç»Ÿå·²å¯åŠ¨ï¼Œæ—¥å¿—æ–‡ä»¶: {log_filename}")
    return logger

def save_cache(data, cache_type):
    """
    ä¿å­˜æ•°æ®åˆ°ç¼“å­˜æ–‡ä»¶
    
    Args:
        data: è¦ç¼“å­˜çš„æ•°æ®
        cache_type: ç¼“å­˜ç±»å‹ ('daily_data' æˆ– 'shares_data')
    """
    logger = logging.getLogger(__name__)
    cache_data = {}
    if os.path.exists(CACHE_FILE):
        try:
            with open(CACHE_FILE, 'rb') as f:
                cache_data = pickle.load(f)
        except:
            cache_data = {}
    
    cache_data[cache_type] = {
        'data': data,
        'timestamp': time.time()
    }
    
    with open(CACHE_FILE, 'wb') as f:
        pickle.dump(cache_data, f)
    logger.info(f"ğŸ’¾ {cache_type} æ•°æ®å·²ç¼“å­˜")

def load_cache(cache_type):
    """
    ä»ç¼“å­˜æ–‡ä»¶åŠ è½½æ•°æ®
    
    Args:
        cache_type: ç¼“å­˜ç±»å‹ ('daily_data' æˆ– 'shares_data')
    
    Returns:
        ç¼“å­˜çš„æ•°æ®ï¼Œå¦‚æœç¼“å­˜æ— æ•ˆæˆ–ä¸å­˜åœ¨åˆ™è¿”å›None
    """
    logger = logging.getLogger(__name__)
    if not os.path.exists(CACHE_FILE):
        return None
    
    try:
        with open(CACHE_FILE, 'rb') as f:
            cache_data = pickle.load(f)
        
        if cache_type not in cache_data:
            return None
        
        cached_item = cache_data[cache_type]
        cache_time = cached_item['timestamp']
        current_time = time.time()
        
        # æ£€æŸ¥ç¼“å­˜æ˜¯å¦è¿‡æœŸï¼ˆ2å°æ—¶ = 7200ç§’ï¼‰
        if current_time - cache_time > CACHE_DURATION_HOURS * 3600:
            logger.info(f"â° {cache_type} ç¼“å­˜å·²è¿‡æœŸ")
            return None
        
        logger.info(f"ğŸ“‚ ä½¿ç”¨ {cache_type} ç¼“å­˜æ•°æ®")
        return cached_item['data']
    
    except Exception as e:
        logger.error(f"âŒ åŠ è½½ {cache_type} ç¼“å­˜å¤±è´¥: {e}")
        return None

# æ²ªæ·±300æˆåˆ†è‚¡åˆ—è¡¨ï¼ˆå·²è¿‡æ»¤æ‰2010å¹´ä¹‹å‰æ²¡æœ‰äº¤æ˜“æ•°æ®çš„è‚¡ç¥¨ï¼‰
# åŸå§‹æ•°é‡: 300, æœ‰æ•ˆæ•°é‡: 176
CSI300_FILTERED_STOCKS = [
    '000001.SZ', '000002.SZ', '000063.SZ', '000100.SZ', '000157.SZ',
    '000301.SZ', '000338.SZ', '000408.SZ', '000425.SZ', '000538.SZ',
    '000568.SZ', '000596.SZ', '000617.SZ', '000625.SZ', '000630.SZ',
    '000651.SZ', '000661.SZ', '000708.SZ', '000725.SZ', '000768.SZ',
    '000776.SZ', '000786.SZ', '000792.SZ', '000800.SZ', '000807.SZ',
    '000858.SZ', '000876.SZ', '000895.SZ', '000938.SZ', '000963.SZ',
    '000975.SZ', '000977.SZ', '000983.SZ', '000999.SZ', '002001.SZ',
    '002027.SZ', '002028.SZ', '002049.SZ', '002050.SZ', '002074.SZ',
    '002129.SZ', '002142.SZ', '002179.SZ', '002180.SZ', '002230.SZ',
    '002236.SZ', '002241.SZ', '002252.SZ', '002304.SZ', '002311.SZ',
    '002352.SZ', '002371.SZ', '002415.SZ', '002422.SZ', '002459.SZ',
    '002460.SZ', '002463.SZ', '002466.SZ', '002475.SZ', '002493.SZ',
    '300014.SZ', '300015.SZ', '300033.SZ', '300059.SZ', '300122.SZ',
    '300124.SZ', '302132.SZ', '600000.SH', '600009.SH', '600010.SH',
    '600011.SH', '600015.SH', '600016.SH', '600018.SH', '600019.SH',
    '600026.SH', '600027.SH', '600028.SH', '600029.SH', '600030.SH',
    '600031.SH', '600036.SH', '600039.SH', '600048.SH', '600050.SH',
    '600061.SH', '600066.SH', '600085.SH', '600089.SH', '600104.SH',
    '600111.SH', '600115.SH', '600150.SH', '600160.SH', '600161.SH',
    '600176.SH', '600183.SH', '600188.SH', '600196.SH', '600219.SH',
    '600233.SH', '600276.SH', '600309.SH', '600332.SH', '600346.SH',
    '600362.SH', '600372.SH', '600377.SH', '600406.SH', '600415.SH',
    '600426.SH', '600436.SH', '600438.SH', '600460.SH', '600482.SH',
    '600489.SH', '600515.SH', '600519.SH', '600547.SH', '600570.SH',
    '600584.SH', '600585.SH', '600588.SH', '600600.SH', '600660.SH',
    '600674.SH', '600690.SH', '600741.SH', '600760.SH', '600795.SH',
    '600803.SH', '600809.SH', '600845.SH', '600875.SH', '600886.SH',
    '600887.SH', '600893.SH', '600900.SH', '600999.SH', '601006.SH',
    '601009.SH', '601088.SH', '601111.SH', '601117.SH', '601166.SH',
    '601169.SH', '601186.SH', '601288.SH', '601318.SH', '601328.SH',
    '601377.SH', '601390.SH', '601398.SH', '601600.SH', '601601.SH',
    '601607.SH', '601618.SH', '601628.SH', '601668.SH', '601688.SH',
    '601699.SH', '601766.SH', '601788.SH', '601808.SH', '601818.SH',
    '601857.SH', '601872.SH', '601877.SH', '601888.SH', '601898.SH',
    '601899.SH', '601919.SH', '601939.SH', '601988.SH', '601989.SH',
    '601998.SH'
]

def get_csi300_filtered_stocks():
    """
    è·å–æ²ªæ·±300æˆåˆ†è‚¡åˆ—è¡¨ï¼ˆå·²è¿‡æ»¤æ‰2010å¹´ä¹‹å‰æ²¡æœ‰äº¤æ˜“æ•°æ®çš„è‚¡ç¥¨ï¼‰
    
    Returns:
        list: åŒ…å«176åªè‚¡ç¥¨ä»£ç çš„åˆ—è¡¨
    """
    return CSI300_FILTERED_STOCKS.copy()



def get_true_quarterly_profit_data(stock_code, start_year=2010, max_retries=3):
    """
    è·å–è‚¡ç¥¨çœŸæ­£çš„å­£åº¦ç›ˆåˆ©æ•°æ®ï¼ˆä½¿ç”¨'æŒ‰æŠ¥å‘ŠæœŸ'å‚æ•°ï¼Œæ”¯æŒç¼“å­˜ï¼‰
    
    Args:
        stock_code: è‚¡ç¥¨ä»£ç ï¼ˆå¯ä»¥åŒ…å«.SZ/.SHåç¼€ï¼‰
        start_year: å¼€å§‹å¹´ä»½
        max_retries: æœ€å¤§é‡è¯•æ¬¡æ•°
    
    Returns:
        dict: åŒ…å«å­£åº¦æ•°æ®çš„å­—å…¸
    """
    # å°è¯•ä»ç¼“å­˜åŠ è½½è´¢åŠ¡æ•°æ®
    cached_data = load_cache('financial_data')
    if cached_data is not None and stock_code in cached_data:
        return cached_data[stock_code]
    
    # æå–6ä½æ•°å­—ä»£ç ï¼ˆå»æ‰.SZ/.SHåç¼€ï¼‰
    if '.' in stock_code:
        clean_code = stock_code.split('.')[0]
    else:
        clean_code = stock_code
    
    logger = logging.getLogger(__name__)
    logger.info(f"è·å– {stock_code} ({clean_code}) çš„å­£åº¦è´¢åŠ¡æ•°æ®...")
    
    # é‡è¯•æœºåˆ¶
    for attempt in range(max_retries):
        try:
            # ä½¿ç”¨'æŒ‰æŠ¥å‘ŠæœŸ'å‚æ•°è·å–å­£åº¦æ•°æ®
            df = ak.stock_financial_benefit_ths(symbol=clean_code, indicator="æŒ‰æŠ¥å‘ŠæœŸ")
            
            if df is None or df.empty:
                if attempt < max_retries - 1:
                    logger.warning(f"ç¬¬{attempt + 1}æ¬¡å°è¯•å¤±è´¥ï¼Œæ­£åœ¨é‡è¯•...")
                    time.sleep(1)  # ç­‰å¾…1ç§’åé‡è¯•
                    continue
                else:
                    return {'error': f'æ— æ³•è·å–è‚¡ç¥¨{stock_code}çš„è´¢åŠ¡æ•°æ®ï¼ˆå·²é‡è¯•{max_retries}æ¬¡ï¼‰'}
            
            # ç¡®ä¿æŠ¥å‘ŠæœŸæ˜¯å­—ç¬¦ä¸²ç±»å‹
            df['æŠ¥å‘ŠæœŸ'] = df['æŠ¥å‘ŠæœŸ'].astype(str)
            
            # ç­›é€‰æŒ‡å®šå¹´ä»½ä¹‹åçš„æ•°æ®
            df_filtered = df[df['æŠ¥å‘ŠæœŸ'].str[:4].astype(int) >= start_year].copy()
            
            # åªä¿ç•™å­£åº¦æ•°æ®ï¼ˆåŒ…å«å…·ä½“æ—¥æœŸçš„æŠ¥å‘ŠæœŸï¼‰
            quarterly_df = df_filtered[df_filtered['æŠ¥å‘ŠæœŸ'].str.contains('-', na=False)].copy()
            
            # æ•°æ®è·å–æˆåŠŸï¼Œå¤„ç†å­£åº¦æ•°æ®
            if quarterly_df.empty:
                if attempt < max_retries - 1:
                    logger.warning(f"ç¬¬{attempt + 1}æ¬¡å°è¯•è·å–åˆ°ç©ºæ•°æ®ï¼Œæ­£åœ¨é‡è¯•...")
                    time.sleep(1)
                    continue
                else:
                    return {'error': f'è‚¡ç¥¨{stock_code}æ²¡æœ‰å­£åº¦æ•°æ®ï¼ˆå·²é‡è¯•{max_retries}æ¬¡ï¼‰'}
            
            # æŒ‰æŠ¥å‘ŠæœŸæ’åºï¼ˆæœ€æ–°çš„åœ¨å‰ï¼‰
            quarterly_df = quarterly_df.sort_values('æŠ¥å‘ŠæœŸ', ascending=False)
            
            quarterly_data = []
            
            for _, row in quarterly_df.iterrows():
                report_period = row['æŠ¥å‘ŠæœŸ']
                
                try:
                    # è§£æå¹´ä»½å’Œå­£åº¦
                    year = int(report_period[:4])
                    
                    if '-03-31' in report_period:
                        quarter = 'Q1'
                    elif '-06-30' in report_period:
                        quarter = 'Q2'
                    elif '-09-30' in report_period:
                        quarter = 'Q3'
                    elif '-12-31' in report_period:
                        quarter = 'Q4'
                    else:
                        continue  # è·³è¿‡éæ ‡å‡†å­£åº¦æŠ¥å‘ŠæœŸ
                    
                    # æå–ç´¯è®¡è´¢åŠ¡æ•°æ®
                    cumulative_net_profit = safe_convert_to_float(row.get('*å‡€åˆ©æ¶¦'))
                    cumulative_revenue = safe_convert_to_float(row.get('*è¥ä¸šæ€»æ”¶å…¥'))
                    cumulative_parent_net_profit = safe_convert_to_float(row.get('*å½’å±äºæ¯å…¬å¸æ‰€æœ‰è€…çš„å‡€åˆ©æ¶¦'))
                    diluted_eps = safe_convert_to_float(row.get('ï¼ˆäºŒï¼‰ç¨€é‡Šæ¯è‚¡æ”¶ç›Š'))
                    
                    # è®¡ç®—å•å­£åº¦å‡€åˆ©æ¶¦ï¼ˆä»ç´¯è®¡å€¼è½¬æ¢ä¸ºå•å­£åº¦å€¼ï¼‰
                    single_quarter_net_profit = cumulative_net_profit
                    single_quarter_revenue = cumulative_revenue
                    single_quarter_parent_net_profit = cumulative_parent_net_profit
                    
                    if quarter == 'Q2':
                        # Q2å•å­£åº¦ = Q2ç´¯è®¡ - Q1ç´¯è®¡
                        q1_period = f"{year}-03-31"
                        q1_row = quarterly_df[quarterly_df['æŠ¥å‘ŠæœŸ'] == q1_period]
                        if not q1_row.empty:
                            q1_net_profit = safe_convert_to_float(q1_row.iloc[0].get('*å‡€åˆ©æ¶¦'))
                            q1_revenue = safe_convert_to_float(q1_row.iloc[0].get('*è¥ä¸šæ€»æ”¶å…¥'))
                            q1_parent_net_profit = safe_convert_to_float(q1_row.iloc[0].get('*å½’å±äºæ¯å…¬å¸æ‰€æœ‰è€…çš„å‡€åˆ©æ¶¦'))
                            if q1_net_profit is not None and cumulative_net_profit is not None:
                                single_quarter_net_profit = cumulative_net_profit - q1_net_profit
                            if q1_revenue is not None and cumulative_revenue is not None:
                                single_quarter_revenue = cumulative_revenue - q1_revenue
                            if q1_parent_net_profit is not None and cumulative_parent_net_profit is not None:
                                single_quarter_parent_net_profit = cumulative_parent_net_profit - q1_parent_net_profit
                    elif quarter == 'Q3':
                        # Q3å•å­£åº¦ = Q3ç´¯è®¡ - Q2ç´¯è®¡
                        q2_period = f"{year}-06-30"
                        q2_row = quarterly_df[quarterly_df['æŠ¥å‘ŠæœŸ'] == q2_period]
                        if not q2_row.empty:
                            q2_net_profit = safe_convert_to_float(q2_row.iloc[0].get('*å‡€åˆ©æ¶¦'))
                            q2_revenue = safe_convert_to_float(q2_row.iloc[0].get('*è¥ä¸šæ€»æ”¶å…¥'))
                            q2_parent_net_profit = safe_convert_to_float(q2_row.iloc[0].get('*å½’å±äºæ¯å…¬å¸æ‰€æœ‰è€…çš„å‡€åˆ©æ¶¦'))
                            if q2_net_profit is not None and cumulative_net_profit is not None:
                                single_quarter_net_profit = cumulative_net_profit - q2_net_profit
                            if q2_revenue is not None and cumulative_revenue is not None:
                                single_quarter_revenue = cumulative_revenue - q2_revenue
                            if q2_parent_net_profit is not None and cumulative_parent_net_profit is not None:
                                single_quarter_parent_net_profit = cumulative_parent_net_profit - q2_parent_net_profit
                    elif quarter == 'Q4':
                        # Q4å•å­£åº¦ = Q4ç´¯è®¡ - Q3ç´¯è®¡
                        q3_period = f"{year}-09-30"
                        q3_row = quarterly_df[quarterly_df['æŠ¥å‘ŠæœŸ'] == q3_period]
                        if not q3_row.empty:
                            q3_net_profit = safe_convert_to_float(q3_row.iloc[0].get('*å‡€åˆ©æ¶¦'))
                            q3_revenue = safe_convert_to_float(q3_row.iloc[0].get('*è¥ä¸šæ€»æ”¶å…¥'))
                            q3_parent_net_profit = safe_convert_to_float(q3_row.iloc[0].get('*å½’å±äºæ¯å…¬å¸æ‰€æœ‰è€…çš„å‡€åˆ©æ¶¦'))
                            if q3_net_profit is not None and cumulative_net_profit is not None:
                                single_quarter_net_profit = cumulative_net_profit - q3_net_profit
                            if q3_revenue is not None and cumulative_revenue is not None:
                                single_quarter_revenue = cumulative_revenue - q3_revenue
                            if q3_parent_net_profit is not None and cumulative_parent_net_profit is not None:
                                single_quarter_parent_net_profit = cumulative_parent_net_profit - q3_parent_net_profit
                    
                    profit_data = {
                        'æŠ¥å‘ŠæœŸ': report_period,
                        'å¹´ä»½': year,
                        'å­£åº¦': quarter,
                        'å‡€åˆ©æ¶¦': single_quarter_net_profit,  # ä½¿ç”¨å•å­£åº¦å‡€åˆ©æ¶¦
                        'è¥ä¸šæ€»æ”¶å…¥': single_quarter_revenue,  # ä½¿ç”¨å•å­£åº¦è¥æ”¶
                        'å½’å±æ¯å…¬å¸å‡€åˆ©æ¶¦': single_quarter_parent_net_profit,  # ä½¿ç”¨å•å­£åº¦å½’æ¯å‡€åˆ©æ¶¦
                        'ç¨€é‡Šæ¯è‚¡æ”¶ç›Š': diluted_eps,
                        'ç´¯è®¡å‡€åˆ©æ¶¦': cumulative_net_profit,  # ä¿ç•™ç´¯è®¡å€¼ç”¨äºè°ƒè¯•
                    }
                    
                    quarterly_data.append(profit_data)
                    
                except Exception as e:
                    logger.error(f"å¤„ç†æŠ¥å‘ŠæœŸ {report_period} æ—¶å‡ºé”™: {str(e)}")
                    continue
            
            # è®¡ç®—æ»šåŠ¨4å­£åº¦ç´¯è®¡ç›ˆåˆ©
            quarterly_data = calculate_rolling_profit(quarterly_data)
            
            # æ•°æ®å¤„ç†æˆåŠŸï¼Œè¿”å›ç»“æœ
            return {
                'stock_code': stock_code,
                'quarterly_data': quarterly_data,
                'total_quarters': len(quarterly_data)
            }
             
        except Exception as e:
            if attempt < max_retries - 1:
                logger.warning(f"ç¬¬{attempt + 1}æ¬¡å°è¯•å‡ºé”™: {str(e)}ï¼Œæ­£åœ¨é‡è¯•...")
                time.sleep(1)  # ç­‰å¾…1ç§’åé‡è¯•
                continue
            else:
                logger.error(f"âŒ è·å– {stock_code} å­£åº¦æ•°æ®å¤±è´¥: {str(e)}")
                return {'error': f'è·å–è‚¡ç¥¨{stock_code}æ•°æ®æ—¶å‡ºé”™ï¼ˆå·²é‡è¯•{max_retries}æ¬¡ï¼‰: {str(e)}'}
    
    # å¦‚æœæ‰€æœ‰é‡è¯•éƒ½å¤±è´¥äº†ï¼ˆç†è®ºä¸Šä¸åº”è¯¥åˆ°è¾¾è¿™é‡Œï¼‰
    return {'error': f'è·å–è‚¡ç¥¨{stock_code}æ•°æ®å¤±è´¥ï¼Œå·²é‡è¯•{max_retries}æ¬¡'}

def calculate_rolling_profit(quarterly_data):
    """
    è®¡ç®—æ»šåŠ¨4å­£åº¦ç´¯è®¡ç›ˆåˆ©ï¼ˆåŒ…æ‹¬æœ¬å­£åº¦ï¼‰
    
    Args:
        quarterly_data: å­£åº¦æ•°æ®åˆ—è¡¨ï¼ŒæŒ‰æ—¶é—´å€’åºæ’åˆ—
    
    Returns:
        list: æ·»åŠ äº†æ»šåŠ¨4å­£åº¦ç´¯è®¡ç›ˆåˆ©çš„å­£åº¦æ•°æ®
    """
    # æŒ‰æ—¶é—´æ­£åºæ’åˆ—ä»¥ä¾¿è®¡ç®—æ»šåŠ¨æ•°æ®
    sorted_data = sorted(quarterly_data, key=lambda x: (x['å¹´ä»½'], x['å­£åº¦']))
    
    for i, quarter in enumerate(sorted_data):
        # è®¡ç®—å½“å‰å­£åº¦åŠä¹‹å‰3ä¸ªå­£åº¦çš„ç´¯è®¡ç›ˆåˆ©ï¼ˆå…±4ä¸ªå­£åº¦ï¼‰
        rolling_profit = 0
        rolling_revenue = 0
        rolling_parent_profit = 0
        valid_quarters = 0
        
        # å‘å‰æŸ¥æ‰¾æœ€å¤š4ä¸ªå­£åº¦çš„æ•°æ®
        for j in range(max(0, i-3), i+1):
            if j < len(sorted_data):
                net_profit = sorted_data[j]['å‡€åˆ©æ¶¦']
                revenue = sorted_data[j]['è¥ä¸šæ€»æ”¶å…¥']
                parent_profit = sorted_data[j]['å½’å±æ¯å…¬å¸å‡€åˆ©æ¶¦']
                
                if net_profit is not None:
                    rolling_profit += net_profit
                if revenue is not None:
                    rolling_revenue += revenue
                if parent_profit is not None:
                    rolling_parent_profit += parent_profit
                
                valid_quarters += 1
        
        # åªæœ‰å½“æœ‰å®Œæ•´çš„4ä¸ªå­£åº¦æ•°æ®æ—¶æ‰è®¾ç½®æ»šåŠ¨æ•°æ®ï¼Œå¦åˆ™è®¾ç½®ä¸ºNone
        if valid_quarters >= 4:
            quarter['æ»šåŠ¨4å­£åº¦å‡€åˆ©æ¶¦'] = rolling_profit if rolling_profit != 0 else None
            quarter['æ»šåŠ¨4å­£åº¦è¥ä¸šæ”¶å…¥'] = rolling_revenue if rolling_revenue != 0 else None
            quarter['æ»šåŠ¨4å­£åº¦å½’å±æ¯å…¬å¸å‡€åˆ©æ¶¦'] = rolling_parent_profit if rolling_parent_profit != 0 else None
        else:
            quarter['æ»šåŠ¨4å­£åº¦å‡€åˆ©æ¶¦'] = None
            quarter['æ»šåŠ¨4å­£åº¦è¥ä¸šæ”¶å…¥'] = None
            quarter['æ»šåŠ¨4å­£åº¦å½’å±æ¯å…¬å¸å‡€åˆ©æ¶¦'] = None
        
        quarter['æ»šåŠ¨å­£åº¦æ•°'] = valid_quarters
    
    # æ¢å¤æŒ‰æ—¶é—´å€’åºæ’åˆ—
    return sorted(sorted_data, key=lambda x: (x['å¹´ä»½'], x['å­£åº¦']), reverse=True)

def get_quarter_end_date(year, quarter):
    """
    è·å–å­£åº¦æœ€åä¸€å¤©çš„æ—¥æœŸ
    
    Args:
        year: å¹´ä»½
        quarter: å­£åº¦ï¼ˆQ1, Q2, Q3, Q4ï¼‰
    
    Returns:
        str: æ—¥æœŸå­—ç¬¦ä¸² (YYYY-MM-DD)
    """
    if quarter == 'Q1':
        return f"{year}-03-31"
    elif quarter == 'Q2':
        return f"{year}-06-30"
    elif quarter == 'Q3':
        return f"{year}-09-30"
    elif quarter == 'Q4':
        return f"{year}-12-31"
    else:
        raise ValueError(f"æ— æ•ˆçš„å­£åº¦: {quarter}")

def get_stock_market_cap(stock_code, date, max_retries=3):
    """
    è·å–æŒ‡å®šæ—¥æœŸè‚¡ç¥¨çš„å¸‚å€¼
    
    Args:
        stock_code: è‚¡ç¥¨ä»£ç 
        date: æ—¥æœŸå­—ç¬¦ä¸² (YYYY-MM-DD)
        max_retries: æœ€å¤§é‡è¯•æ¬¡æ•°
    
    Returns:
        float or None: å¸‚å€¼ï¼ˆå…ƒï¼‰ï¼Œå¦‚æœè·å–å¤±è´¥è¿”å›None
    """
    # æå–6ä½æ•°å­—ä»£ç 
    if '.' in stock_code:
        clean_code = stock_code.split('.')[0]
    else:
        clean_code = stock_code
    
    for attempt in range(max_retries):
        try:
            # è·å–è‚¡ç¥¨åŸºæœ¬ä¿¡æ¯ï¼ˆåŒ…å«æ€»è‚¡æœ¬ï¼‰
            stock_info = ak.stock_individual_info_em(symbol=clean_code)
            if stock_info is None or stock_info.empty:
                if attempt < max_retries - 1:
                    time.sleep(0.5)
                    continue
                return None
            
            # è·å–æ€»è‚¡æœ¬ï¼ˆä¸‡è‚¡ï¼‰
            total_shares_wan = None
            for _, row in stock_info.iterrows():
                if row['item'] == 'æ€»è‚¡æœ¬':
                    total_shares_wan = safe_convert_to_float(row['value'])
                    break
            
            if total_shares_wan is None:
                if attempt < max_retries - 1:
                    time.sleep(0.5)
                    continue
                return None
            
            # è½¬æ¢ä¸ºè‚¡æ•°ï¼ˆè‚¡ï¼‰
            total_shares = total_shares_wan * 10000
            
            # è·å–æŒ‡å®šæ—¥æœŸçš„è‚¡ä»·
            try:
                # å°è¯•è·å–æŒ‡å®šæ—¥æœŸå‰åçš„å†å²æ•°æ®
                start_date = (datetime.strptime(date, '%Y-%m-%d') - timedelta(days=10)).strftime('%Y%m%d')
                end_date = (datetime.strptime(date, '%Y-%m-%d') + timedelta(days=10)).strftime('%Y%m%d')
                
                hist_data = ak.stock_zh_a_hist(symbol=clean_code, period="daily", 
                                             start_date=start_date, end_date=end_date, adjust="")
                
                if hist_data is None or hist_data.empty:
                    if attempt < max_retries - 1:
                        time.sleep(0.5)
                        continue
                    return None
                
                # æŸ¥æ‰¾æœ€æ¥è¿‘ç›®æ ‡æ—¥æœŸçš„äº¤æ˜“æ—¥
                hist_data['æ—¥æœŸ'] = pd.to_datetime(hist_data['æ—¥æœŸ'])
                target_date = datetime.strptime(date, '%Y-%m-%d')
                
                # æ‰¾åˆ°å°äºç­‰äºç›®æ ‡æ—¥æœŸçš„æœ€è¿‘äº¤æ˜“æ—¥
                valid_data = hist_data[hist_data['æ—¥æœŸ'] <= target_date]
                if valid_data.empty:
                    # å¦‚æœæ²¡æœ‰å°äºç­‰äºç›®æ ‡æ—¥æœŸçš„æ•°æ®ï¼Œå–æœ€æ—©çš„æ•°æ®
                    valid_data = hist_data
                
                if valid_data.empty:
                    if attempt < max_retries - 1:
                        time.sleep(0.5)
                        continue
                    return None
                
                # å–æœ€è¿‘çš„æ”¶ç›˜ä»·
                latest_data = valid_data.iloc[-1]
                close_price = float(latest_data['æ”¶ç›˜'])
                
                # è®¡ç®—å¸‚å€¼
                market_cap = total_shares * close_price
                return market_cap
                
            except Exception as e:
                if attempt < max_retries - 1:
                    time.sleep(0.5)
                    continue
                return None
                
        except Exception as e:
            if attempt < max_retries - 1:
                time.sleep(0.5)
                continue
            return None
    
    return None

def get_all_stocks_daily_data(stock_codes, start_date, end_date):
    """
    è·å–æ‰€æœ‰è‚¡ç¥¨çš„æ—¥çº¿æ•°æ®ï¼ˆæ”¯æŒç¼“å­˜ï¼‰
    
    Args:
        stock_codes: è‚¡ç¥¨ä»£ç åˆ—è¡¨
        start_date: å¼€å§‹æ—¥æœŸ
        end_date: ç»“æŸæ—¥æœŸ
    
    Returns:
        dict: æ‰€æœ‰è‚¡ç¥¨çš„æ—¥çº¿æ•°æ®
    """
    # å°è¯•ä»ç¼“å­˜åŠ è½½æ•°æ®
    cached_data = load_cache('daily_data')
    if cached_data is not None:
        return cached_data
    
    logger = logging.getLogger(__name__)
    logger.info(f"å¼€å§‹è·å– {len(stock_codes)} åªè‚¡ç¥¨çš„æ—¥çº¿æ•°æ®...")
    all_daily_data = {}
    success_count = 0
    failed_count = 0
    failed_examples = []
    
    for i, stock_code in enumerate(stock_codes, 1):
        if i % 20 == 0:
            logger.info(f"è¿›åº¦: {i}/{len(stock_codes)}")
        
        try:
            # è·å–æ—¥çº¿æ•°æ®ï¼Œakshareéœ€è¦6ä½æ•°å­—ä»£ç 
            symbol = stock_code.split('.')[0]  # å»æ‰åç¼€ï¼Œåªä¿ç•™6ä½æ•°å­—
            daily_data = ak.stock_zh_a_hist(symbol=symbol, period="daily", 
                                          start_date=start_date, end_date=end_date, adjust="")
            
            if not daily_data.empty:
                # è½¬æ¢æ—¥æœŸæ ¼å¼å¹¶è®¾ç½®ä¸ºç´¢å¼•
                daily_data['æ—¥æœŸ'] = pd.to_datetime(daily_data['æ—¥æœŸ'])
                daily_data.set_index('æ—¥æœŸ', inplace=True)
                all_daily_data[stock_code] = daily_data
                success_count += 1
            else:
                failed_count += 1
                if len(failed_examples) < 5:
                    failed_examples.append(f"{stock_code}({symbol}): ç©ºæ•°æ®")
                
        except Exception as e:
            failed_count += 1
            if len(failed_examples) < 5:
                failed_examples.append(f"{stock_code}: {str(e)[:50]}")
            continue
        
        # æ·»åŠ å»¶è¿Ÿé¿å…è¯·æ±‚è¿‡å¿«
        time.sleep(0.05)
    
    logger.info(f"âœ… æ—¥çº¿æ•°æ®è·å–å®Œæˆ: æˆåŠŸ {success_count}, å¤±è´¥ {failed_count}")
    if failed_examples:
        logger.warning(f"å¤±è´¥ç¤ºä¾‹: {failed_examples}")
    
    # ä¿å­˜åˆ°ç¼“å­˜
    save_cache(all_daily_data, 'daily_data')
    return all_daily_data

def calculate_quarterly_market_cap_optimized(results, all_daily_data, shares_data, quarterly_stats):
    """
    åŸºäºå·²è·å–çš„æ—¥çº¿æ•°æ®å’Œæ€»è‚¡æœ¬æ•°æ®è®¡ç®—æ¯ä¸ªå­£åº¦æ‰€æœ‰è‚¡ç¥¨çš„å¸‚å€¼æ€»å’Œ
    
    Args:
        results: è‚¡ç¥¨å­£åº¦æ•°æ®ç»“æœ
        all_daily_data: æ‰€æœ‰è‚¡ç¥¨çš„æ—¥çº¿æ•°æ®
        quarterly_stats: å­£åº¦ç»Ÿè®¡æ•°æ®ï¼ˆç”¨äºè®¡ç®—å¸‚ç›ˆç‡ï¼‰
        shares_data: æ‰€æœ‰è‚¡ç¥¨çš„æ€»è‚¡æœ¬æ•°æ®
    
    Returns:
        dict: æ¯ä¸ªå­£åº¦çš„å¸‚å€¼æ€»å’Œ
    """
    logger = logging.getLogger(__name__)
    logger.info("å¼€å§‹è®¡ç®—æ¯ä¸ªå­£åº¦çš„å¸‚å€¼æ€»å’Œ...")
    
    # æ”¶é›†æ‰€æœ‰å­£åº¦
    all_quarters = set()
    for stock_code, stock_data in results.items():
        for quarter_data in stock_data['quarterly_data']:
            year = quarter_data['å¹´ä»½']
            quarter = quarter_data['å­£åº¦']
            quarter_key = f"{year}-{quarter}"
            all_quarters.add((year, quarter, quarter_key))
    
    quarterly_market_caps = {}
    
    # æŒ‰å­£åº¦è®¡ç®—å¸‚å€¼
    for year, quarter, quarter_key in sorted(all_quarters, reverse=True):
        logger.info(f"è®¡ç®— {quarter_key} å­£åº¦å¸‚å€¼...")
        
        quarter_end_date = get_quarter_end_date(year, quarter)
        quarter_end_datetime = pd.to_datetime(quarter_end_date)
        
        total_market_cap = 0
        success_count = 0
        failed_count = 0
        debug_info = []
        
        # è·å–è¯¥å­£åº¦æœ‰æ•°æ®çš„æ‰€æœ‰è‚¡ç¥¨
        stocks_in_quarter = []
        for stock_code, stock_data in results.items():
            for quarter_data in stock_data['quarterly_data']:
                if quarter_data['å¹´ä»½'] == year and quarter_data['å­£åº¦'] == quarter:
                    stocks_in_quarter.append(stock_code)
                    break
        
        logger.info(f"è¯¥å­£åº¦æœ‰è´¢åŠ¡æ•°æ®çš„è‚¡ç¥¨æ•°: {len(stocks_in_quarter)}")
        
        # å­˜å‚¨æ¯åªè‚¡ç¥¨çš„è¯¦ç»†å¸‚å€¼ä¿¡æ¯
        stock_details = {}
        
        # è®¡ç®—æ¯åªè‚¡ç¥¨çš„å¸‚å€¼
        for stock_code in stocks_in_quarter:
            try:
                # æ£€æŸ¥æ˜¯å¦æœ‰æ—¥çº¿æ•°æ®
                if stock_code not in all_daily_data:
                    failed_count += 1
                    debug_info.append(f"{stock_code}: æ— æ—¥çº¿æ•°æ®")
                    continue
                
                # æ£€æŸ¥æ˜¯å¦æœ‰æ€»è‚¡æœ¬æ•°æ®
                if stock_code not in shares_data:
                    failed_count += 1
                    debug_info.append(f"{stock_code}: æ— æ€»è‚¡æœ¬æ•°æ®")
                    continue
                
                daily_data = all_daily_data[stock_code]
                total_shares = shares_data[stock_code]
                
                # æ‰¾åˆ°å­£åº¦æœ€åä¸€å¤©æˆ–ä¹‹å‰æœ€è¿‘çš„äº¤æ˜“æ—¥
                available_dates = daily_data.index[daily_data.index <= quarter_end_datetime]
                if len(available_dates) == 0:
                    failed_count += 1
                    debug_info.append(f"{stock_code}: æ— å¯¹åº”æ—¥æœŸçš„è‚¡ä»·æ•°æ®")
                    continue
                
                target_date = available_dates.max()
                close_price = daily_data.loc[target_date, 'æ”¶ç›˜']
                
                # è®¡ç®—å¸‚å€¼
                market_cap = close_price * total_shares
                total_market_cap += market_cap
                success_count += 1
                
                # å­˜å‚¨è‚¡ç¥¨è¯¦ç»†ä¿¡æ¯
                stock_details[stock_code] = {
                    'market_cap': market_cap,
                    'close_price': close_price,
                    'total_shares': total_shares,
                    'date': target_date.strftime('%Y-%m-%d')
                }
                
            except Exception as e:
                failed_count += 1
                debug_info.append(f"{stock_code}: è®¡ç®—é”™è¯¯ - {str(e)}")
                continue
        
        # è®¡ç®—å¸‚ç›ˆç‡ (PE ratio)
        pe_ratio = None
        if quarter_key in quarterly_stats:
            rolling_4q_profit = quarterly_stats[quarter_key].get('rolling_4q_profit', 0)
            if rolling_4q_profit > 0:
                pe_ratio = total_market_cap / rolling_4q_profit
        
        quarterly_market_caps[quarter_key] = {
            'total_market_cap': total_market_cap,
            'success_count': success_count,
            'failed_count': failed_count,
            'date': quarter_end_date,
            'pe_ratio': pe_ratio,
            'stock_details': stock_details
        }
        
        logger.info(f"âœ… {quarter_key}: æ€»å¸‚å€¼ {total_market_cap/1000000000000:.2f} ä¸‡äº¿å…ƒ")
        logger.info(f"æˆåŠŸè·å–: {success_count}, å¤±è´¥: {failed_count}")
        
        # å¦‚æœå¤±è´¥è¾ƒå¤šï¼Œæ˜¾ç¤ºéƒ¨åˆ†è°ƒè¯•ä¿¡æ¯
        if failed_count > success_count and len(debug_info) > 0:
            logger.warning(f"è°ƒè¯•ä¿¡æ¯ï¼ˆå‰5ä¸ªå¤±è´¥åŸå› ï¼‰: {debug_info[:5]}")
    
    return quarterly_market_caps

def get_total_shares_batch(stock_codes):
    """
    æ‰¹é‡è·å–è‚¡ç¥¨çš„æ€»è‚¡æœ¬ä¿¡æ¯ï¼ˆæ”¯æŒç¼“å­˜ï¼‰
    
    Args:
        stock_codes: è‚¡ç¥¨ä»£ç åˆ—è¡¨
    
    Returns:
        dict: è‚¡ç¥¨ä»£ç åˆ°æ€»è‚¡æœ¬çš„æ˜ å°„
    """
    # å°è¯•ä»ç¼“å­˜åŠ è½½æ•°æ®
    cached_data = load_cache('shares_data')
    if cached_data is not None:
        return cached_data
    
    logger = logging.getLogger(__name__)
    logger.info(f"å¼€å§‹è·å– {len(stock_codes)} åªè‚¡ç¥¨çš„æ€»è‚¡æœ¬ä¿¡æ¯...")
    shares_data = {}
    success_count = 0
    failed_count = 0
    failed_examples = []
    
    for i, stock_code in enumerate(stock_codes, 1):
        if i % 20 == 0:
            logger.info(f"è¿›åº¦: {i}/{len(stock_codes)}")
        
        try:
            # è·å–è‚¡ç¥¨åŸºæœ¬ä¿¡æ¯ï¼Œakshareéœ€è¦6ä½æ•°å­—ä»£ç 
            symbol = stock_code.split('.')[0]  # å»æ‰åç¼€ï¼Œåªä¿ç•™6ä½æ•°å­—
            stock_info = ak.stock_individual_info_em(symbol=symbol)
            
            # æŸ¥æ‰¾æ€»è‚¡æœ¬ä¿¡æ¯
            total_shares = None
            for _, row in stock_info.iterrows():
                item_name = str(row['item'])
                if 'æ€»è‚¡æœ¬' in item_name:
                    total_shares_value = row['value']
                    # ç›´æ¥ä½¿ç”¨æ•°å€¼ï¼Œå› ä¸ºakshareè¿”å›çš„å·²ç»æ˜¯æ•°å­—æ ¼å¼
                    if pd.notna(total_shares_value):
                        total_shares = float(total_shares_value)
                    break
            
            if total_shares is not None and total_shares > 0:
                shares_data[stock_code] = total_shares
                success_count += 1
            else:
                failed_count += 1
                if len(failed_examples) < 5:
                    failed_examples.append(f"{stock_code}: æ€»è‚¡æœ¬ä¸ºç©ºæˆ–0")
                
        except Exception as e:
            failed_count += 1
            if len(failed_examples) < 5:
                failed_examples.append(f"{stock_code}: {str(e)[:50]}")
            continue
        
        # æ·»åŠ å»¶è¿Ÿé¿å…è¯·æ±‚è¿‡å¿«
        time.sleep(0.05)
    
    logger.info(f"âœ… æ€»è‚¡æœ¬è·å–å®Œæˆ: æˆåŠŸ {success_count}, å¤±è´¥ {failed_count}")
    if failed_examples:
        logger.warning(f"å¤±è´¥ç¤ºä¾‹: {failed_examples}")
    
    # ä¿å­˜åˆ°ç¼“å­˜
    save_cache(shares_data, 'shares_data')
    return shares_data

def safe_convert_to_float(value):
    """
    å®‰å…¨åœ°å°†å€¼è½¬æ¢ä¸ºæµ®ç‚¹æ•°ï¼Œå¤„ç†å¸¦å•ä½çš„å­—ç¬¦ä¸²
    
    Args:
        value: è¦è½¬æ¢çš„å€¼
    
    Returns:
        float or None: è½¬æ¢åçš„æ•°å€¼
    """
    if pd.isna(value) or value == '' or value == '--':
        return None
    
    try:
        # å¦‚æœå·²ç»æ˜¯æ•°å­—ï¼Œç›´æ¥è¿”å›
        if isinstance(value, (int, float)):
            return float(value)
        
        # è½¬æ¢ä¸ºå­—ç¬¦ä¸²å¤„ç†
        value_str = str(value).strip()
        
        # ç§»é™¤é€—å·
        value_str = value_str.replace(',', '')
        
        # å¤„ç†å¸¦å•ä½çš„æƒ…å†µ
        if 'äº¿' in value_str:
            number = float(value_str.replace('äº¿', ''))
            return number * 100000000  # è½¬æ¢ä¸ºå…ƒ
        elif 'ä¸‡' in value_str:
            number = float(value_str.replace('ä¸‡', ''))
            return number * 10000  # è½¬æ¢ä¸ºå…ƒ
        else:
            return float(value_str)
    
    except (ValueError, TypeError):
        return None

def analyze_all_stocks_true_quarterly(start_year=2010):
    """
    åˆ†ææ‰€æœ‰è‚¡ç¥¨çš„çœŸå®å­£åº¦ç›ˆåˆ©æƒ…å†µ
    
    Args:
        start_year: å¼€å§‹å¹´ä»½
    
    Returns:
        dict: åˆ†æç»“æœ
    """
    # åˆå§‹åŒ–æ—¥å¿—ç³»ç»Ÿ
    logger = setup_logging()
    logger.info(f"å¼€å§‹åˆ†ææ²ªæ·±300è‚¡ç¥¨çš„çœŸå®å­£åº¦ç›ˆåˆ©æƒ…å†µï¼ˆä»{start_year}å¹´å¼€å§‹ï¼‰")
    
    # å°è¯•ä»ç¼“å­˜åŠ è½½è´¢åŠ¡æ•°æ®
    cached_financial_data = load_cache('financial_data')
    if cached_financial_data is not None:
        logger.info(f"ğŸ“‚ ä½¿ç”¨è´¢åŠ¡æ•°æ®ç¼“å­˜ï¼ŒåŒ…å« {len(cached_financial_data)} åªè‚¡ç¥¨")
        results = cached_financial_data
        success_count = len(results)
        failed_stocks = []
        total_stocks = len(results)
    else:
        stocks = get_csi300_filtered_stocks()
        total_stocks = len(stocks)
        
        results = {}
        success_count = 0
        failed_stocks = []
        
        for i, stock_code in enumerate(stocks, 1):
            logger.info(f"å¤„ç†ç¬¬ {i}/{total_stocks} åªè‚¡ç¥¨: {stock_code}")
            
            # è·å–å­£åº¦æ•°æ®
            data = get_true_quarterly_profit_data(stock_code, start_year)
            
            if 'error' in data:
                logger.error(f"âŒ å¤±è´¥: {data['error']}")
                failed_stocks.append(stock_code)
            else:
                logger.info(f"âœ… æˆåŠŸ: è·å–åˆ° {data['total_quarters']} ä¸ªå­£åº¦æ•°æ®")
                results[stock_code] = data
                success_count += 1
            
            # æ·»åŠ å»¶è¿Ÿé¿å…è¯·æ±‚è¿‡å¿«
            time.sleep(0.2)
        
        # ä¿å­˜è´¢åŠ¡æ•°æ®åˆ°ç¼“å­˜
        if results:
            save_cache(results, 'financial_data')
    
    # ç”Ÿæˆå­£åº¦ç»Ÿè®¡åˆ†æ
    quarterly_stats = generate_quarterly_statistics(results)
    
    # è·å–æ‰€æœ‰è‚¡ç¥¨çš„æ—¥çº¿æ•°æ®ï¼ˆä»2010å¹´å¼€å§‹åˆ°ç°åœ¨ï¼‰
    all_stock_codes = list(results.keys())
    start_date_str = f"{start_year}0101"  # akshareéœ€è¦YYYYMMDDæ ¼å¼
    # ä½¿ç”¨å½“å‰æ—¥æœŸä½œä¸ºç»“æŸæ—¥æœŸï¼Œä½†ç¼“å­˜é”®åä½¿ç”¨æ—¥æœŸèŒƒå›´è€Œä¸æ˜¯å…·ä½“æ—¥æœŸ
    end_date_str = datetime.now().strftime('%Y%m%d')  # akshareéœ€è¦YYYYMMDDæ ¼å¼
    all_daily_data = get_all_stocks_daily_data(all_stock_codes, start_date_str, end_date_str)
    
    # æ‰¹é‡è·å–æ‰€æœ‰è‚¡ç¥¨çš„æ€»è‚¡æœ¬ä¿¡æ¯
    shares_data = get_total_shares_batch(all_stock_codes)
    
    # åŸºäºæ—¥çº¿æ•°æ®å’Œæ€»è‚¡æœ¬æ•°æ®è®¡ç®—æ¯ä¸ªå­£åº¦çš„å¸‚å€¼æ€»å’Œ
    quarterly_market_caps = calculate_quarterly_market_cap_optimized(results, all_daily_data, shares_data, quarterly_stats)
    
    # æ„å»ºæ¸…ç†åçš„ç®€æ´æ•°æ®ç»“æ„
    cleaned_data = {
        "metadata": {
            "analysis_type": "Quarterly Analysis",
            "start_year": start_year,
            "total_stocks": total_stocks,
            "total_quarters": len(quarterly_stats),
            "generated_at": datetime.now().strftime('%Y-%m-%d')
        },
        "quarterly_data": {}
    }
    
    # åˆå¹¶æ¯ä¸ªå­£åº¦çš„ç»Ÿè®¡æ•°æ®å’Œå¸‚å€¼æ•°æ®
    for quarter in quarterly_stats.keys():
        quarter_stats = quarterly_stats.get(quarter, {})
        market_data = quarterly_market_caps.get(quarter, {})
        
        # æ£€æŸ¥æ˜¯å¦æœ‰æœ‰æ•ˆçš„æ»šåŠ¨4Qæ•°æ®
        rolling_4q_count = quarter_stats.get('rolling_4q_count', 0)
        has_valid_rolling_data = rolling_4q_count > 0
        
        cleaned_data["quarterly_data"][quarter] = {
            "total_profit": quarter_stats.get('total_profit', 0),
            "total_revenue": quarter_stats.get('total_revenue', 0),
            "rolling_4q_profit": quarter_stats.get('rolling_4q_profit', 0) if has_valid_rolling_data else None,
            "rolling_4q_revenue": quarter_stats.get('rolling_4q_revenue', 0) if has_valid_rolling_data else None,
            "stock_count": quarter_stats.get('stock_count', 0),
            "profitable_count": quarter_stats.get('profitable_count', 0),
            "loss_count": quarter_stats.get('loss_count', 0),
            "profit_rate": quarter_stats.get('profit_rate', 0),
            "total_market_cap": market_data.get('total_market_cap', 0),
            "pe_ratio": market_data.get('pe_ratio', 0),
            "date": market_data.get('date', ''),
            "stock_details": market_data.get('stock_details', {})
        }

    logger.info("=== çœŸå®å­£åº¦åˆ†æå®Œæˆ ===")
    logger.info(f"æ€»è‚¡ç¥¨æ•°: {total_stocks}")
    logger.info(f"æˆåŠŸè·å–: {success_count}")
    logger.info(f"è·å–å¤±è´¥: {len(failed_stocks)}")
    
    # ä¿å­˜æ¸…ç†åçš„ç®€æ´ç»“æœåˆ°JSONæ–‡ä»¶
    output_file = 'true_quarterly_analysis.json'
    with open(output_file, 'w', encoding='utf-8') as f:
        json.dump(cleaned_data, f, ensure_ascii=False, indent=2)
    
    logger.info(f"æ¸…ç†åçš„åˆ†æç»“æœå·²ä¿å­˜åˆ°: {output_file}")
    logger.info(f"æ•°æ®ç»“æ„: metadata + {len(cleaned_data['quarterly_data'])} ä¸ªå­£åº¦æ•°æ®")
    
    # è¿”å›åŒ…å«è¯¦ç»†è‚¡ç¥¨æ•°æ®çš„å®Œæ•´ç»“æœ
    return {
        'cleaned_data': cleaned_data,
        'results': results
    }

def generate_quarterly_statistics(results):
    """
    ç”Ÿæˆå­£åº¦ç»Ÿè®¡æ•°æ®
    
    Args:
        results: è‚¡ç¥¨å­£åº¦æ•°æ®ç»“æœ
    
    Returns:
        dict: å­£åº¦ç»Ÿè®¡æ•°æ®
    """
    from collections import defaultdict
    
    quarterly_stats = defaultdict(lambda: {
        'total_profit': 0,
        'total_revenue': 0,
        'profitable_count': 0,
        'loss_count': 0,
        'stock_count': 0,
        'rolling_4q_profit': 0,
        'rolling_4q_revenue': 0,
        'rolling_4q_parent_profit': 0,
        'rolling_4q_count': 0
    })
    
    # æŒ‰å­£åº¦ç»Ÿè®¡
    for stock_code, stock_data in results.items():
        for quarter_data in stock_data['quarterly_data']:
            year = quarter_data['å¹´ä»½']
            quarter = quarter_data['å­£åº¦']
            quarter_key = f"{year}-{quarter}"
            
            net_profit = quarter_data['å‡€åˆ©æ¶¦']
            revenue = quarter_data['è¥ä¸šæ€»æ”¶å…¥']
            
            quarterly_stats[quarter_key]['stock_count'] += 1
            
            if net_profit is not None:
                quarterly_stats[quarter_key]['total_profit'] += net_profit
                if net_profit > 0:
                    quarterly_stats[quarter_key]['profitable_count'] += 1
                else:
                    quarterly_stats[quarter_key]['loss_count'] += 1
            
            if revenue is not None:
                quarterly_stats[quarter_key]['total_revenue'] += revenue
            
            # ç´¯è®¡æ»šåŠ¨4å­£åº¦æ•°æ®
            rolling_profit = quarter_data.get('æ»šåŠ¨4å­£åº¦å‡€åˆ©æ¶¦')
            rolling_revenue = quarter_data.get('æ»šåŠ¨4å­£åº¦è¥ä¸šæ”¶å…¥')
            rolling_parent_profit = quarter_data.get('æ»šåŠ¨4å­£åº¦å½’å±æ¯å…¬å¸å‡€åˆ©æ¶¦')
            
            if rolling_profit is not None:
                quarterly_stats[quarter_key]['rolling_4q_profit'] += rolling_profit
                quarterly_stats[quarter_key]['rolling_4q_count'] += 1
            
            if rolling_revenue is not None:
                quarterly_stats[quarter_key]['rolling_4q_revenue'] += rolling_revenue
            
            if rolling_parent_profit is not None:
                quarterly_stats[quarter_key]['rolling_4q_parent_profit'] += rolling_parent_profit
    
    # è®¡ç®—ç›ˆåˆ©ç‡
    for quarter_key, stats in quarterly_stats.items():
        total_with_profit_data = stats['profitable_count'] + stats['loss_count']
        if total_with_profit_data > 0:
            stats['profit_rate'] = stats['profitable_count'] / total_with_profit_data * 100
        else:
            stats['profit_rate'] = 0
    
    # è½¬æ¢ä¸ºæ™®é€šå­—å…¸å¹¶æ’åº
    sorted_stats = dict(sorted(quarterly_stats.items(), reverse=True))
    
    return sorted_stats




def print_detailed_stock_info(analysis_result, logger, target_quarters):
    """
    æ‰“å°æŒ‡å®šå­£åº¦æ¯åªè‚¡ç¥¨çš„è¯¦ç»†å¸‚å€¼å’Œå‡€åˆ©æ¶¦ä¿¡æ¯
    
    Args:
        analysis_result: åˆ†æç»“æœï¼ˆåŒ…å«cleaned_dataå’Œresultsï¼‰
        logger: æ—¥å¿—è®°å½•å™¨
        target_quarters: ç›®æ ‡å­£åº¦åˆ—è¡¨ï¼Œå¦‚['2010-Q4', '2011-Q4']
    """
    results = analysis_result.get('results', {})
    quarterly_data = analysis_result.get('cleaned_data', {}).get('quarterly_data', {})
    
    for quarter_key in target_quarters:
        try:
            if quarter_key not in quarterly_data:
                logger.info(f"æœªæ‰¾åˆ°å­£åº¦ {quarter_key} çš„æ•°æ®")
                continue
            
            logger.info(f"å¼€å§‹å¤„ç†å­£åº¦ {quarter_key}")
            logger.info(f"\n=== {quarter_key} è¯¦ç»†è‚¡ç¥¨ä¿¡æ¯ ===")
            logger.info(f"{'è‚¡ç¥¨ä»£ç ':<12} {'å‡€åˆ©æ¶¦(ä¸‡å…ƒ)':<15} {'å¸‚å€¼(äº¿å…ƒ)':<15} {'æ”¶ç›˜ä»·(å…ƒ)':<12} {'æ€»è‚¡æœ¬(ä¸‡è‚¡)':<15}")
            logger.info("-" * 80)
            
            year, quarter = quarter_key.split('-')
            year = int(year)
            quarter_num = int(quarter[1:])
            
            total_market_cap_check = 0
            total_profit_check = 0
            stock_count = 0
            
            # è·å–è¯¥å­£åº¦çš„å¸‚å€¼è¯¦æƒ…
            quarter_stats = quarterly_data.get(quarter_key, {})
            stock_details = quarter_stats.get('stock_details', {})
            
            # æ”¶é›†æ‰€æœ‰è‚¡ç¥¨æ•°æ®ç”¨äºæ’åº
            stock_data_list = []
            
            # éå†æ‰€æœ‰è‚¡ç¥¨ï¼Œæ‰¾åˆ°è¯¥å­£åº¦çš„æ•°æ®
            for stock_code, stock_info in results.items():
                quarterly_list = stock_info.get('quarterly_data', [])
                
                # æŸ¥è¯•è¯¥å­£åº¦çš„æ•°æ®
                quarter_data = None
                quarter_str = f'Q{quarter_num}'  # è½¬æ¢ä¸ºQ1, Q2, Q3, Q4æ ¼å¼
                for q_data in quarterly_list:
                    if q_data.get('å¹´ä»½') == year and q_data.get('å­£åº¦') == quarter_str:
                        quarter_data = q_data
                        break
                
                if quarter_data:
                    net_profit = quarter_data.get('å‡€åˆ©æ¶¦', 0) or 0  # å•å­£åº¦å‡€åˆ©æ¶¦ï¼Œå•ä½ï¼šä¸‡å…ƒ
                    
                    # è·å–å¸‚å€¼ä¿¡æ¯
                    if stock_code in stock_details:
                        market_cap_info = stock_details[stock_code]
                        market_cap_yi = market_cap_info['market_cap'] / 100000000  # è½¬æ¢ä¸ºäº¿å…ƒ
                        close_price = market_cap_info['close_price']
                        total_shares_wan = market_cap_info['total_shares'] / 10000  # è½¬æ¢ä¸ºä¸‡è‚¡
                        
                        stock_data_list.append({
                            'stock_code': stock_code,
                            'net_profit': net_profit,
                            'market_cap_yi': market_cap_yi,
                            'close_price': close_price,
                            'total_shares_wan': total_shares_wan,
                            'market_cap_raw': market_cap_info['market_cap']
                        })
                        
                        total_market_cap_check += market_cap_info['market_cap']
                        total_profit_check += net_profit * 10000  # è½¬æ¢ä¸ºå…ƒ
                        stock_count += 1
                    else:
                        # å¦‚æœæ²¡æœ‰å¸‚å€¼æ•°æ®ï¼Œåªæ˜¾ç¤ºå‡€åˆ©æ¶¦
                        stock_data_list.append({
                            'stock_code': stock_code,
                            'net_profit': net_profit,
                            'market_cap_yi': 0,
                            'close_price': 'N/A',
                            'total_shares_wan': 'N/A',
                            'market_cap_raw': 0
                        })
                        total_profit_check += net_profit * 10000  # è½¬æ¢ä¸ºå…ƒ
                        stock_count += 1
            
            # æŒ‰å¸‚å€¼ä»å¤§åˆ°å°æ’åº
            stock_data_list.sort(key=lambda x: x['market_cap_raw'], reverse=True)
            
            # æ‰“å°æ’åºåçš„è‚¡ç¥¨ä¿¡æ¯
            for stock_data in stock_data_list:
                if stock_data['close_price'] == 'N/A':
                    logger.info(f"{stock_data['stock_code']:<12} {stock_data['net_profit']:<15.0f} {'N/A':<15} {'N/A':<12} {'N/A':<15}")
                else:
                    logger.info(f"{stock_data['stock_code']:<12} {stock_data['net_profit']:<15.0f} {stock_data['market_cap_yi']:<15.2f} {stock_data['close_price']:<12.2f} {stock_data['total_shares_wan']:<15.0f}")
            
            # æ˜¾ç¤ºæ±‡æ€»ä¿¡æ¯
            logger.info("-" * 80)
            logger.info(f"æ±‡æ€»: è‚¡ç¥¨æ•°={stock_count}, æ€»å‡€åˆ©æ¶¦={total_profit_check/100000000:.0f}äº¿å…ƒ, æ€»å¸‚å€¼={total_market_cap_check/1000000000000:.2f}ä¸‡äº¿å…ƒ")
            
            # ä¸å­£åº¦ç»Ÿè®¡æ•°æ®å¯¹æ¯”
            quarter_stats = quarterly_data.get(quarter_key, {})
            official_profit = quarter_stats.get('total_profit', 0) / 100000000
            official_market_cap = quarter_stats.get('total_market_cap', 0) / 1000000000000
            official_stock_count = quarter_stats.get('stock_count', 0)
            
            logger.info(f"å®˜æ–¹ç»Ÿè®¡: è‚¡ç¥¨æ•°={official_stock_count}, æ€»å‡€åˆ©æ¶¦={official_profit:.0f}äº¿å…ƒ, æ€»å¸‚å€¼={official_market_cap:.2f}ä¸‡äº¿å…ƒ")
        
        except Exception as e:
            logger.error(f"å¤„ç†å­£åº¦ {quarter_key} æ—¶å‘ç”Ÿé”™è¯¯: {str(e)}")
            continue


def print_quarterly_summary(analysis_result, logger):
    """
    æ‰“å°å­£åº¦åˆ†ææ‘˜è¦
    
    Args:
        analysis_result: åˆ†æç»“æœï¼ˆåŒ…å«cleaned_dataå’Œresultsï¼‰
        logger: æ—¥å¿—è®°å½•å™¨
    """
    logger.info("=== çœŸå®å­£åº¦ç›ˆåˆ©åˆ†ææ‘˜è¦ ===")
    
    quarterly_data = analysis_result['cleaned_data']['quarterly_data']
    
    logger.info("æ‰€æœ‰å­£åº¦ç›ˆåˆ©æƒ…å†µ:")
    logger.info(f"{'å­£åº¦':<12} {'æ€»å‡€åˆ©æ¶¦(äº¿)':<16} {'æ€»è¥æ”¶(ä¸‡äº¿)':<16} {'æ»šåŠ¨4Qå‡€åˆ©æ¶¦(äº¿)':<20} {'æ€»å¸‚å€¼(ä¸‡äº¿)':<16} {'å¸‚ç›ˆç‡':<11} {'ç›ˆåˆ©ç‡':<11} {'è‚¡ç¥¨æ•°':<8}")
    logger.info("-" * 130)
    
    # æŒ‰å­£åº¦å€’åºæ’åˆ—ï¼Œæ˜¾ç¤ºæ‰€æœ‰å­£åº¦
    sorted_quarters = sorted(quarterly_data.keys(), reverse=True)
    for i, quarter_key in enumerate(sorted_quarters):
        # æ˜¾ç¤ºæ‰€æœ‰å­£åº¦æ•°æ®
        
        stats = quarterly_data[quarter_key]
        total_profit_yi = stats['total_profit'] / 100000000
        total_revenue_wanyi = stats['total_revenue'] / 1000000000000
        rolling_4q_profit_yi = stats['rolling_4q_profit'] / 100000000 if stats['rolling_4q_profit'] is not None else 0
        profit_rate = stats['profit_rate']
        stock_count = stats['stock_count']
        total_market_cap_wanyi = stats['total_market_cap'] / 1000000000000
        pe_ratio = stats['pe_ratio']
        pe_ratio_str = f"{pe_ratio:.1f}" if pe_ratio is not None and pe_ratio > 0 else "N/A"
        rolling_4q_profit_str = f"{rolling_4q_profit_yi:.0f}" if stats['rolling_4q_profit'] is not None else "N/A"
        
        logger.info(f"{quarter_key:<12} {total_profit_yi:<16.0f} {total_revenue_wanyi:<16.1f} {rolling_4q_profit_str:<20} {total_market_cap_wanyi:<16.1f} {pe_ratio_str:<11} {profit_rate:<10.1f}% {stock_count:<8}")
    
    # è¯¦ç»†è‚¡ç¥¨ä¿¡æ¯å°†åœ¨mainå‡½æ•°ä¸­å•ç‹¬è°ƒç”¨
    
    # æ˜¾ç¤ºå¸‚å€¼ç»Ÿè®¡æ‘˜è¦
    if quarterly_data:
        logger.info("=== å¸‚å€¼ç»Ÿè®¡æ‘˜è¦ ===")
        total_quarters_with_market_cap = len(quarterly_data)
        logger.info(f"å·²è®¡ç®—å¸‚å€¼çš„å­£åº¦æ•°: {total_quarters_with_market_cap}")
        
        latest_quarter = sorted_quarters[0]
        latest_data = quarterly_data[latest_quarter]
        logger.info(f"æœ€æ–°å­£åº¦ ({latest_quarter}):")
        logger.info(f"  æ€»å¸‚å€¼: {latest_data['total_market_cap']/1000000000000:.2f} ä¸‡äº¿å…ƒ")
        logger.info(f"  è‚¡ç¥¨æ•°: {latest_data['stock_count']}")
        logger.info(f"  å¸‚ç›ˆç‡: {latest_data['pe_ratio']:.2f}")
        logger.info(f"  æ•°æ®æ—¥æœŸ: {latest_data['date']}")

def print_market_cap_trend_analysis(analysis_result, logger, stock_name_mapping=None):
    """
    æ‰“å°2010åˆ°2011å¹´çš„å¸‚å€¼è¶‹åŠ¿å˜åŒ–è¡¨
    
    Args:
        analysis_result: åˆ†æç»“æœæ•°æ®
        logger: æ—¥å¿—è®°å½•å™¨
        stock_name_mapping: è‚¡ç¥¨ä»£ç åˆ°åç§°çš„æ˜ å°„å­—å…¸
    """
    logger.info("")
    logger.info("=== 2010-2011å¹´å¸‚å€¼è¶‹åŠ¿å˜åŒ–åˆ†æ ===")
    if stock_name_mapping:
        logger.info("è‚¡ç¥¨ä»£ç          è‚¡ç¥¨åç§°              2010-Q4å¸‚å€¼(äº¿)    2011-Q4å¸‚å€¼(äº¿)    å˜åŒ–å€¼(äº¿)       å˜åŒ–ç™¾åˆ†æ¯”(%)")
        logger.info("-" * 120)
    else:
        logger.info("è‚¡ç¥¨ä»£ç          2010-Q4å¸‚å€¼(äº¿)    2011-Q4å¸‚å€¼(äº¿)    å˜åŒ–å€¼(äº¿)       å˜åŒ–ç™¾åˆ†æ¯”(%)")
        logger.info("-" * 100)
    
    # è·å–å­£åº¦æ•°æ®
    quarterly_data = analysis_result.get('cleaned_data', {}).get('quarterly_data', {})
    
    if not quarterly_data:
        logger.info("ç¼ºå°‘å­£åº¦æ•°æ®")
        return
    
    # è·å–2010-Q4å’Œ2011-Q4çš„å¸‚å€¼è¯¦æƒ…
    quarter_2010_q4 = quarterly_data.get('2010-Q4', {})
    quarter_2011_q4 = quarterly_data.get('2011-Q4', {})
    
    stock_details_2010 = quarter_2010_q4.get('stock_details', {})
    stock_details_2011 = quarter_2011_q4.get('stock_details', {})
    
    logger.info(f"2010-Q4æœ‰å¸‚å€¼æ•°æ®çš„è‚¡ç¥¨: {len(stock_details_2010)}åª")
    logger.info(f"2011-Q4æœ‰å¸‚å€¼æ•°æ®çš„è‚¡ç¥¨: {len(stock_details_2011)}åª")
    
    if not stock_details_2010 or not stock_details_2011:
        logger.info("ç¼ºå°‘2010-Q4æˆ–2011-Q4çš„å¸‚å€¼æ•°æ®")
        return
    
    # æ”¶é›†æ‰€æœ‰è‚¡ç¥¨çš„å¸‚å€¼å˜åŒ–æ•°æ®
    trend_data = []
    
    # æ‰¾åˆ°ä¸¤ä¸ªå­£åº¦éƒ½æœ‰æ•°æ®çš„è‚¡ç¥¨
    common_stocks = set(stock_details_2010.keys()) & set(stock_details_2011.keys())
    logger.info(f"ä¸¤ä¸ªå­£åº¦éƒ½æœ‰æ•°æ®çš„è‚¡ç¥¨: {len(common_stocks)}åª")
    
    if not common_stocks:
        logger.info("æ²¡æœ‰æ‰¾åˆ°åŒæ—¶åŒ…å«2010-Q4å’Œ2011-Q4å¸‚å€¼æ•°æ®çš„è‚¡ç¥¨")
        return
    
    for stock_code in common_stocks:
        market_cap_2010 = stock_details_2010[stock_code]['market_cap'] / 100000000  # è½¬æ¢ä¸ºäº¿å…ƒ
        market_cap_2011 = stock_details_2011[stock_code]['market_cap'] / 100000000  # è½¬æ¢ä¸ºäº¿å…ƒ
        
        # è®¡ç®—å˜åŒ–å€¼å’Œç™¾åˆ†æ¯”
        change_value = market_cap_2011 - market_cap_2010
        change_percent = (change_value / market_cap_2010) * 100 if market_cap_2010 > 0 else 0
        
        trend_data.append({
            'stock_code': stock_code,
            'market_cap_2010': market_cap_2010,
            'market_cap_2011': market_cap_2011,
            'change_value': change_value,
            'change_percent': change_percent
        })
    
    if len(trend_data) == 0:
        logger.info("æ²¡æœ‰æ‰¾åˆ°åŒæ—¶åŒ…å«2010-Q4å’Œ2011-Q4å¸‚å€¼æ•°æ®çš„è‚¡ç¥¨")
        return
    
    # æŒ‰2010å¹´å¸‚å€¼æ’åºï¼ˆä»å¤§åˆ°å°ï¼‰
    trend_data.sort(key=lambda x: x['market_cap_2010'], reverse=True)
    
    # æ‰“å°æ‰€æœ‰è‚¡ç¥¨çš„å˜åŒ–æƒ…å†µ
    for i, data in enumerate(trend_data):
        stock_code = data['stock_code']
        market_cap_2010 = data['market_cap_2010']
        market_cap_2011 = data['market_cap_2011']
        change_value = data['change_value']
        change_percent = data['change_percent']
        
        # è·å–è‚¡ç¥¨åç§°
        stock_name = stock_name_mapping.get(stock_code, "æœªçŸ¥") if stock_name_mapping else ""
        
        # æ ¼å¼åŒ–è¾“å‡º
        change_sign = "+" if change_value >= 0 else ""
        percent_sign = "+" if change_percent >= 0 else ""
        
        if stock_name_mapping:
            # åŒ…å«è‚¡ç¥¨åç§°çš„æ ¼å¼
            logger.info(f"{stock_code:<12} {stock_name:<20} {market_cap_2010:>12.2f}      {market_cap_2011:>12.2f}      {change_sign}{change_value:>10.2f}      {percent_sign}{change_percent:>8.1f}%")
        else:
            # åŸå§‹æ ¼å¼ï¼ˆä¸åŒ…å«è‚¡ç¥¨åç§°ï¼‰
            logger.info(f"{stock_code:<12} {market_cap_2010:>12.2f}      {market_cap_2011:>12.2f}      {change_sign}{change_value:>10.2f}      {percent_sign}{change_percent:>8.1f}%")
    
    # ç»Ÿè®¡æ±‡æ€»
    total_market_cap_2010 = sum(d['market_cap_2010'] for d in trend_data)
    total_market_cap_2011 = sum(d['market_cap_2011'] for d in trend_data)
    total_change = total_market_cap_2011 - total_market_cap_2010
    total_change_percent = (total_change / total_market_cap_2010) * 100 if total_market_cap_2010 > 0 else 0
    
    # è®¡ç®—ä¸Šæ¶¨å’Œä¸‹è·Œçš„è‚¡ç¥¨æ•°é‡
    rising_stocks = [d for d in trend_data if d['change_percent'] > 0]
    falling_stocks = [d for d in trend_data if d['change_percent'] < 0]
    unchanged_stocks = len(trend_data) - len(rising_stocks) - len(falling_stocks)
    
    # æ‰“å°ç»Ÿè®¡ä¿¡æ¯
    logger.info("-" * 100)
    logger.info(f"ç»Ÿè®¡ä¿¡æ¯:")
    logger.info(f"2010-Q4æ€»å¸‚å€¼: {total_market_cap_2010/10000:.2f}ä¸‡äº¿å…ƒ")
    logger.info(f"2011-Q4æ€»å¸‚å€¼: {total_market_cap_2011/10000:.2f}ä¸‡äº¿å…ƒ")
    logger.info(f"æ€»å˜åŒ–å€¼: {total_change/10000:+.2f}ä¸‡äº¿å…ƒ ({total_change_percent:+.2f}%)")
    logger.info("")
    logger.info("=== æ¶¨è·Œåˆ†å¸ƒç»Ÿè®¡ ===")
    logger.info(f"ä¸Šæ¶¨è‚¡ç¥¨: {len(rising_stocks)}åª ({len(rising_stocks)/len(trend_data)*100:.1f}%)")
    logger.info(f"ä¸‹è·Œè‚¡ç¥¨: {len(falling_stocks)}åª ({len(falling_stocks)/len(trend_data)*100:.1f}%)")
    logger.info(f"æŒå¹³è‚¡ç¥¨: {unchanged_stocks}åª ({unchanged_stocks/len(trend_data)*100:.1f}%)")
    
    if rising_stocks:
        avg_rise = sum(d['change_percent'] for d in rising_stocks) / len(rising_stocks)
        logger.info(f"ä¸Šæ¶¨è‚¡ç¥¨å¹³å‡æ¶¨å¹…: {avg_rise:.1f}%")
    
    if falling_stocks:
        avg_fall = sum(d['change_percent'] for d in falling_stocks) / len(falling_stocks)
        logger.info(f"ä¸‹è·Œè‚¡ç¥¨å¹³å‡è·Œå¹…: {avg_fall:.1f}%")
    
    logger.info("-" * 100)

def main():
    """
    ä¸»å‡½æ•°
    """
    # åˆ†æçœŸå®å­£åº¦æ•°æ®
    full_result = analyze_all_stocks_true_quarterly(start_year=2010)
    analysis_result = full_result['cleaned_data']
    
    # è·å–loggerå®ä¾‹
    logger = logging.getLogger(__name__)
    
    # è·å–è‚¡ç¥¨åç§°æ˜ å°„
    stock_name_mapping = get_stock_name_mapping()
    
    # æ‰“å°è¯¦ç»†è‚¡ç¥¨ä¿¡æ¯
    print_detailed_stock_info(full_result, logger, ['2010-Q4', '2011-Q4'])
    
    # æ‰“å°2010-2011å¹´å¸‚å€¼è¶‹åŠ¿å˜åŒ–åˆ†æ
    print_market_cap_trend_analysis(full_result, logger, stock_name_mapping)
    
    # æ‰“å°æ‘˜è¦
    print_quarterly_summary(full_result, logger)
    
    logger.info("çœŸå®å­£åº¦åˆ†æå®Œæˆï¼")
    logger.info("ä¸»è¦æ”¹è¿›:")
    logger.info("â€¢ ä½¿ç”¨'æŒ‰æŠ¥å‘ŠæœŸ'å‚æ•°è·å–çœŸæ­£çš„å­£åº¦æ•°æ®")
    logger.info("â€¢ æ•°æ®åŒ…å«Q1ã€Q2ã€Q3ã€Q4å››ä¸ªå­£åº¦çš„è¯¦ç»†ä¿¡æ¯")
    logger.info("â€¢ å¯ä»¥åˆ†æå­£åº¦é—´çš„ç›ˆåˆ©å˜åŒ–è¶‹åŠ¿")
    logger.info("â€¢ æä¾›æ›´ç²¾ç¡®çš„å­£åº¦ç›ˆåˆ©ç»Ÿè®¡")

if __name__ == "__main__":
    main()